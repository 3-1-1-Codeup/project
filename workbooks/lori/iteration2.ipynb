{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin 2nd Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangle as w\n",
    "import model as m\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model.py (customized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrangle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# Model Prep\n",
    "\n",
    "\n",
    "def dummy_dept(df):\n",
    "    # dummy dept feature\n",
    "    dummy_df =  pd.get_dummies(df['dept'])\n",
    "    # Name the new columns\n",
    "    dummy_df.columns = ['animal_care_services', 'code_enforcement_services', \n",
    "                        'customer_services', 'development_services', \n",
    "                        'metro_health', 'parks_and_rec',\n",
    "                        'solid_waste_management', 'trans_and_cap_improvements', \n",
    "                        'unknown_dept']\n",
    "    # add the dummies to the data frame\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df\n",
    "#-----------------------------------------------------------------------------    \n",
    "def dummy_call_reason(df):\n",
    "    # dummy dept feature\n",
    "    dummy_df =  pd.get_dummies(df['call_reason'])\n",
    "    # Name the new columns\n",
    "    dummy_df.columns = ['buildings', 'business', 'cleanup', 'code',\n",
    "                        'customer_service', 'field', 'land',\n",
    "                        'license', 'misc', 'storm', 'streets', 'trades', \n",
    "                        'traffic', 'waste']\n",
    "    # add the dummies to the data frame\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df\n",
    "#-----------------------------------------------------------------------------\n",
    "def make_source_id_dummies(df):\n",
    "    '''This function takes in the cleaned dataframe, makes dummy variables of the source id column, readds the names of the\n",
    "    dummy columns and returns the concatenated dummy dataframe to the original dataframe.'''\n",
    "    #make dummies\n",
    "    dummy_df = pd.get_dummies(df['source_id'])\n",
    "    #add back column names\n",
    "    dummy_df.columns = ['web_portal', '311_mobile_app', 'constituent_call', 'internal_services_requests']\n",
    "    # concatenate dummies to the cleaned data frame\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df\n",
    "\n",
    "#-------------------------------\n",
    "#zipcode dummies\n",
    "def dummy_zipcodes(df):\n",
    "    dummy = pd.get_dummies(df['zipcode'])\n",
    "    df = pd.concat([df, dummy], axis=1)\n",
    "    return df\n",
    "\n",
    "#-------------------------------\n",
    "def keep_info(df):\n",
    "    df.drop(df.columns.difference(['dept','call_reason', 'source_id', 'level_of_delay',\n",
    "                                   'council_district', 'resolution_days_due', 'district_0', 'district_1', 'district_2',\n",
    "                                   'district_3', 'district_4','district_5', 'district_6', 'district_7', 'district_8', \n",
    "                                   'district_9','district_10', 'per_capita_income', 'zipcode']), 1, inplace=True)\n",
    "    return df\n",
    "\n",
    "#--------------------------------\n",
    "def model_df():\n",
    "    '''This function reads in the clean 311 dataframe, applies all of the above functions to prepare it for modeling. \n",
    "    The function then returns a cleaned dataframe ready for modeling.'''\n",
    "    df= wrangle.clean_311(wrangle.get_311_data())\n",
    "    df= keep_info(df)\n",
    "    df= dummy_dept(df)\n",
    "    df= dummy_call_reason(df)\n",
    "    df= make_source_id_dummies(df)\n",
    "    df= dummy_zipcodes(df)\n",
    "\n",
    "    return df\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def split(df, stratify_by= 'level_of_delay'):\n",
    "    \"\"\"\n",
    "    Crude train, validate, test split\n",
    "    To stratify, send in a column name\n",
    "    \"\"\"\n",
    "    if stratify_by == None:\n",
    "        train, test = train_test_split(df, test_size=.2, random_state=319)\n",
    "        train, validate = train_test_split(train, test_size=.3, random_state=319)\n",
    "    else:\n",
    "        train, test = train_test_split(df, test_size=.2, random_state=319, stratify=df[stratify_by])\n",
    "        train, validate = train_test_split(train, test_size=.3, random_state=319, stratify=train[stratify_by])\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "def separate_y(train, validate, test):\n",
    "    '''\n",
    "    This function will take the train, validate, and test dataframes and separate the target variable into its\n",
    "    own panda series\n",
    "    '''\n",
    "    \n",
    "    X_train = train.drop(columns=['level_of_delay'])\n",
    "    y_train = train.level_of_delay\n",
    "    X_validate = validate.drop(columns=['level_of_delay'])\n",
    "    y_validate = validate.level_of_delay\n",
    "    X_test = test.drop(columns=['level_of_delay'])\n",
    "    y_test = test.level_of_delay\n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "#------------------------------------\n",
    "def scale_data(X_train, X_validate, X_test):\n",
    "    '''\n",
    "    This function will scale numeric data using Min Max transform after \n",
    "    it has already been split into train, validate, and test.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    obj_col = []\n",
    "    num_train = X_train.drop(columns = obj_col)\n",
    "    num_validate = X_validate.drop(columns = obj_col)\n",
    "    num_test = X_test.drop(columns = obj_col)\n",
    "    \n",
    "    \n",
    "    # Make the thing\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "   \n",
    "    # we only .fit on the training data\n",
    "    scaler.fit(num_train)\n",
    "    train_scaled = scaler.transform(num_train)\n",
    "    validate_scaled = scaler.transform(num_validate)\n",
    "    test_scaled = scaler.transform(num_test)\n",
    "    \n",
    "    # turn the numpy arrays into dataframes\n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=num_train.columns)\n",
    "    validate_scaled = pd.DataFrame(validate_scaled, columns=num_train.columns)\n",
    "    test_scaled = pd.DataFrame(test_scaled, columns=num_train.columns)\n",
    "    \n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "def split_separate_scale(df, stratify_by= 'level_of_delay'):\n",
    "    '''\n",
    "    This function will take in a dataframe\n",
    "    separate the dataframe into train, validate, and test dataframes\n",
    "    separate the target variable from train, validate and test\n",
    "    then it will scale the numeric variables in train, validate, and test\n",
    "    finally it will return all dataframes individually\n",
    "    '''\n",
    "    \n",
    "    # split data into train, validate, test\n",
    "    train, validate, test = split(df, stratify_by= 'level_of_delay')\n",
    "    \n",
    "     # seperate target variable\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = separate_y(train, validate, test)\n",
    "    \n",
    "    \n",
    "    # scale numeric variable\n",
    "    train_scaled, validate_scaled, test_scaled = scale_data(X_train, X_validate, X_test)\n",
    "    \n",
    "    return train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorisegovia/codeup-data-science/project/workbooks/lori/wrangle.py:331: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df['open_week'] = df.open_date.dt.week\n"
     ]
    }
   ],
   "source": [
    "df = w.clean_311(w.get_311_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open_date                       0\n",
       "due_date                        0\n",
       "closed_date                 43182\n",
       "is_late                         0\n",
       "dept                            0\n",
       "call_reason                     0\n",
       "case_type                       0\n",
       "case_status                     0\n",
       "source_id                       0\n",
       "address                         0\n",
       "council_district                0\n",
       "longitude                       0\n",
       "latitude                        0\n",
       "days_open                       0\n",
       "resolution_days_due             0\n",
       "days_before_or_after_due    43182\n",
       "pct_time_of_used                0\n",
       "level_of_delay                  0\n",
       "district_1                      0\n",
       "district_2                      0\n",
       "district_3                      0\n",
       "district_4                      0\n",
       "district_5                      0\n",
       "district_6                      0\n",
       "district_7                      0\n",
       "district_8                      0\n",
       "district_9                      0\n",
       "district_10                     0\n",
       "voter_turnout_2019              0\n",
       "num_of_registered_voters        0\n",
       "zipcode                         0\n",
       "open_month                      0\n",
       "open_year                       0\n",
       "open_week                       0\n",
       "per_capita_income               0\n",
       "square_miles                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399986, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['days_before_or_after_due'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['closed_date'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open_date                   0\n",
       "due_date                    0\n",
       "closed_date                 0\n",
       "is_late                     0\n",
       "dept                        0\n",
       "call_reason                 0\n",
       "case_type                   0\n",
       "case_status                 0\n",
       "source_id                   0\n",
       "address                     0\n",
       "council_district            0\n",
       "longitude                   0\n",
       "latitude                    0\n",
       "days_open                   0\n",
       "resolution_days_due         0\n",
       "days_before_or_after_due    0\n",
       "pct_time_of_used            0\n",
       "level_of_delay              0\n",
       "district_1                  0\n",
       "district_2                  0\n",
       "district_3                  0\n",
       "district_4                  0\n",
       "district_5                  0\n",
       "district_6                  0\n",
       "district_7                  0\n",
       "district_8                  0\n",
       "district_9                  0\n",
       "district_10                 0\n",
       "voter_turnout_2019          0\n",
       "num_of_registered_voters    0\n",
       "zipcode                     0\n",
       "open_month                  0\n",
       "open_year                   0\n",
       "open_week                   0\n",
       "per_capita_income           0\n",
       "square_miles                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356804, 36)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>is_late</th>\n",
       "      <th>dept</th>\n",
       "      <th>call_reason</th>\n",
       "      <th>case_type</th>\n",
       "      <th>case_status</th>\n",
       "      <th>source_id</th>\n",
       "      <th>address</th>\n",
       "      <th>...</th>\n",
       "      <th>district_9</th>\n",
       "      <th>district_10</th>\n",
       "      <th>voter_turnout_2019</th>\n",
       "      <th>num_of_registered_voters</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>open_month</th>\n",
       "      <th>open_year</th>\n",
       "      <th>open_week</th>\n",
       "      <th>per_capita_income</th>\n",
       "      <th>square_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>YES</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>customer_service</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Constituent Call</td>\n",
       "      <td>2407  WYOMING ST, San Antonio, 78203</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>67656</td>\n",
       "      <td>78203</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>19055</td>\n",
       "      <td>59.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>YES</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>customer_service</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Constituent Call</td>\n",
       "      <td>5102  OLD PEARSALL, San Antonio, 78242</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078</td>\n",
       "      <td>66370</td>\n",
       "      <td>78242</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>18500</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>YES</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>customer_service</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Constituent Call</td>\n",
       "      <td>2223  HOUSTON ST E, San Antonio, 78202</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>67656</td>\n",
       "      <td>78202</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>19055</td>\n",
       "      <td>59.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>YES</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>customer_service</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Constituent Call</td>\n",
       "      <td>2531  PEREZ, San Antonio, 78207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148</td>\n",
       "      <td>68081</td>\n",
       "      <td>78207</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>23967</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>YES</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>customer_service</td>\n",
       "      <td>Complaint</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Constituent Call</td>\n",
       "      <td>8002  GRISSOM RD, San Antonio, 78251</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124</td>\n",
       "      <td>80007</td>\n",
       "      <td>78251</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>23437</td>\n",
       "      <td>38.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     open_date   due_date closed_date is_late              dept  \\\n",
       "551 2017-01-27 2017-02-03  2020-11-19     YES  Customer Service   \n",
       "552 2017-01-27 2017-02-03  2020-11-19     YES  Customer Service   \n",
       "553 2017-02-03 2017-02-10  2020-11-19     YES  Customer Service   \n",
       "554 2017-02-03 2017-02-10  2020-11-19     YES  Customer Service   \n",
       "555 2017-02-28 2017-03-07  2020-11-19     YES  Customer Service   \n",
       "\n",
       "          call_reason  case_type case_status         source_id  \\\n",
       "551  customer_service  Complaint      Closed  Constituent Call   \n",
       "552  customer_service  Complaint      Closed  Constituent Call   \n",
       "553  customer_service  Complaint      Closed  Constituent Call   \n",
       "554  customer_service  Complaint      Closed  Constituent Call   \n",
       "555  customer_service  Complaint      Closed  Constituent Call   \n",
       "\n",
       "                                    address  ...  district_9  district_10  \\\n",
       "551    2407  WYOMING ST, San Antonio, 78203  ...           0            0   \n",
       "552  5102  OLD PEARSALL, San Antonio, 78242  ...           0            0   \n",
       "553  2223  HOUSTON ST E, San Antonio, 78202  ...           0            0   \n",
       "554         2531  PEREZ, San Antonio, 78207  ...           0            0   \n",
       "555    8002  GRISSOM RD, San Antonio, 78251  ...           0            0   \n",
       "\n",
       "     voter_turnout_2019  num_of_registered_voters  zipcode  open_month  \\\n",
       "551               0.086                     67656    78203           1   \n",
       "552               0.078                     66370    78242           1   \n",
       "553               0.086                     67656    78202           2   \n",
       "554               0.148                     68081    78207           2   \n",
       "555               0.124                     80007    78251           2   \n",
       "\n",
       "     open_year open_week  per_capita_income  square_miles  \n",
       "551       2017         4              19055         59.81  \n",
       "552       2017         4              18500         65.21  \n",
       "553       2017         5              19055         59.81  \n",
       "554       2017         5              23967         26.00  \n",
       "555       2017         9              23437         38.44  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356804 entries, 551 to 399979\n",
      "Data columns (total 36 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   open_date                 356804 non-null  datetime64[ns]\n",
      " 1   due_date                  356804 non-null  datetime64[ns]\n",
      " 2   closed_date               356804 non-null  datetime64[ns]\n",
      " 3   is_late                   356804 non-null  object        \n",
      " 4   dept                      356804 non-null  object        \n",
      " 5   call_reason               356804 non-null  object        \n",
      " 6   case_type                 356804 non-null  object        \n",
      " 7   case_status               356804 non-null  object        \n",
      " 8   source_id                 356804 non-null  object        \n",
      " 9   address                   356804 non-null  object        \n",
      " 10  council_district          356804 non-null  int64         \n",
      " 11  longitude                 356804 non-null  float64       \n",
      " 12  latitude                  356804 non-null  float64       \n",
      " 13  days_open                 356804 non-null  float64       \n",
      " 14  resolution_days_due       356804 non-null  int64         \n",
      " 15  days_before_or_after_due  356804 non-null  float64       \n",
      " 16  pct_time_of_used          356804 non-null  float64       \n",
      " 17  level_of_delay            356804 non-null  category      \n",
      " 18  district_1                356804 non-null  uint8         \n",
      " 19  district_2                356804 non-null  uint8         \n",
      " 20  district_3                356804 non-null  uint8         \n",
      " 21  district_4                356804 non-null  uint8         \n",
      " 22  district_5                356804 non-null  uint8         \n",
      " 23  district_6                356804 non-null  uint8         \n",
      " 24  district_7                356804 non-null  uint8         \n",
      " 25  district_8                356804 non-null  uint8         \n",
      " 26  district_9                356804 non-null  uint8         \n",
      " 27  district_10               356804 non-null  uint8         \n",
      " 28  voter_turnout_2019        356804 non-null  float64       \n",
      " 29  num_of_registered_voters  356804 non-null  int64         \n",
      " 30  zipcode                   356804 non-null  object        \n",
      " 31  open_month                356804 non-null  int64         \n",
      " 32  open_year                 356804 non-null  int64         \n",
      " 33  open_week                 356804 non-null  int64         \n",
      " 34  per_capita_income         356804 non-null  int64         \n",
      " 35  square_miles              356804 non-null  float64       \n",
      "dtypes: category(1), datetime64[ns](3), float64(7), int64(7), object(8), uint8(10)\n",
      "memory usage: 74.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('cleanest_311.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zipcode dummies\n",
    "#def dummy_zipcodes(df):\n",
    "    #dummy = pd.get_dummies(df['zipcode'])\n",
    "    #df = pd.concat([df, dummy], axis=1)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy = pd.get_dummies(df['zipcode'])\n",
    "#dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.concat([df, dummy], axis=1)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorisegovia/codeup-data-science/project/workbooks/lori/wrangle.py:331: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df['open_week'] = df.open_date.dt.week\n"
     ]
    }
   ],
   "source": [
    "df = model_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 399986 entries, 0 to 399985\n",
      "Columns: 112 entries, dept to 78288\n",
      "dtypes: category(1), int64(3), object(4), uint8(104)\n",
      "memory usage: 64.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['dept', 'call_reason', \n",
    "        'source_id', 'council_district'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 399986 entries, 0 to 399985\n",
      "Columns: 107 entries, resolution_days_due to 78288\n",
      "dtypes: category(1), int64(2), uint8(104)\n",
      "memory usage: 49.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, train_scaled, validate_scaled, test_scaled = m.split_separate_scale(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extremely Early Response    142657\n",
       "Very Early Response          35776\n",
       "Late Response                17032\n",
       "Early Response               13609\n",
       "On Time Response             11761\n",
       "Very Late Response            2510\n",
       "Extremely Late Response        646\n",
       "Name: level_of_delay, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline\n",
    "train.level_of_delay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline accuracy is: 64.0 %\n"
     ]
    }
   ],
   "source": [
    "#baseline accuracy will be early response\n",
    "baseline = round((train.level_of_delay == 'Extremely Early Response').mean(), 2) *100\n",
    "\n",
    "print(f'The baseline accuracy is: {baseline} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the thing\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "#fit the thing\n",
    "clf = clf.fit(X_train, y_train)\n",
    "#predicitons\n",
    "y_pred = clf.predict(X_train)\n",
    "#probability\n",
    "y_pred_proba = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.64\n"
     ]
    }
   ],
   "source": [
    "#compute the accuracy \n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.64\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "          Early Response       0.00      0.00      0.00      5833\n",
      "Extremely Early Response       0.66      0.97      0.79     61139\n",
      " Extremely Late Response       0.00      0.00      0.00       276\n",
      "           Late Response       0.00      0.00      0.00      7300\n",
      "        On Time Response       0.00      0.00      0.00      5040\n",
      "     Very Early Response       0.31      0.11      0.17     15333\n",
      "      Very Late Response       0.68      0.43      0.53      1076\n",
      "\n",
      "                accuracy                           0.64     95997\n",
      "               macro avg       0.24      0.22      0.21     95997\n",
      "            weighted avg       0.48      0.64      0.54     95997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Produce y_predictions that come from the X_validate\n",
    "y_pred = clf.predict(X_validate)\n",
    "\n",
    "# Compare actual y values (from validate) to predicted y_values from the model run on X_validate\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the thing\n",
    "clf = DecisionTreeClassifier(max_depth=6, random_state=123)\n",
    "#fit the thing\n",
    "clf = clf.fit(X_train, y_train)\n",
    "#predicitons\n",
    "y_pred = clf.predict(X_train)\n",
    "#probability\n",
    "y_pred_proba = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.65\n"
     ]
    }
   ],
   "source": [
    "#compute the accuracy \n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.65\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the thing\n",
    "clf = DecisionTreeClassifier(max_depth=12, random_state=123)\n",
    "#fit the thing\n",
    "clf = clf.fit(X_train, y_train)\n",
    "#predicitons\n",
    "y_pred = clf.predict(X_train)\n",
    "#probability\n",
    "y_pred_proba = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.66\n"
     ]
    }
   ],
   "source": [
    "#compute the accuracy \n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.65\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.case_type.value_counts()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = m.model_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
