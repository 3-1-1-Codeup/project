{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tableau uploads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrangle as w\n",
    "import explore as e\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = w.clean_311(w.get_311_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = df[df.days_before_or_after_due == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.level_of_delay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.level_of_delay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_late.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.days_before_or_after_due.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_time = df[df.level_of_delay == 'On Time Response']\n",
    "very_late = df[df.level_of_delay == 'Very Late Response']\n",
    "early = df[df.level_of_delay == 'Early Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_time.days_before_or_after_due.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_late.days_before_or_after_due.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early.days_before_or_after_due.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.days_before_or_after_due < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_late(days_before_or_after_due):\n",
    "    if days_before_or_after_due < 0:\n",
    "        return 'late'\n",
    "    else:\n",
    "        return 'on time'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get actual amount of late cases\n",
    "df['late'] = df['days_before_or_after_due'].apply(get_late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final2_311.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature to show how long it took to resolve compared to resolution due date\n",
    "#df['days_before_or_after_due'] = df.resolution_days_due - df.days_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = m.model_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrangle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# Model Prep\n",
    "\n",
    "def dummy_dept(df):\n",
    "    # dummy dept feature\n",
    "    dummy_df =  pd.get_dummies(df['dept'])\n",
    "    # Name the new columns\n",
    "    dummy_df.columns = ['animal_care_services', 'code_enforcement_services', \n",
    "                        'customer_services', 'development_services', \n",
    "                        'metro_health', 'parks_and_rec',\n",
    "                        'solid_waste_management', 'trans_and_cap_improvements', \n",
    "                        'unknown_dept']\n",
    "    # add the dummies to the data frame\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df\n",
    "#-----------------------------------------------------------------------------    \n",
    "def dummy_call_reason(df):\n",
    "    # dummy dept feature\n",
    "    dummy_df =  pd.get_dummies(df['call_reason'])\n",
    "    # Name the new columns\n",
    "    dummy_df.columns = ['buildings', 'business', 'cleanup', 'code',\n",
    "                        'customer_service', 'field', 'land',\n",
    "                        'license', 'misc', 'storm', 'streets', 'trades', \n",
    "                        'traffic', 'waste']\n",
    "    # add the dummies to the data frame\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df\n",
    "#-----------------------------------------------------------------------------\n",
    "def make_source_id_dummies(df):\n",
    "    '''This function takes in the cleaned dataframe, makes dummy variables of the source id column, readds the names of the\n",
    "    dummy columns and returns the concatenated dummy dataframe to the original dataframe.'''\n",
    "    #make dummies\n",
    "    dummy_df = pd.get_dummies(df['source_id'])\n",
    "    #add back column names\n",
    "    dummy_df.columns = ['web_portal', '311_mobile_app', 'constituent_call', 'internal_services_requests']\n",
    "    # concatenate dummies to the cleaned data frame\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df\n",
    "\n",
    "#-------------------------------\n",
    "def keep_info(df):\n",
    "    df.drop(df.columns.difference(['days_before_after_due','dept','call_reason', 'source_id', 'level_of_delay',\n",
    "                                   'council_district', 'resolution_days_due', 'district_0', 'district_1', 'district_2',\n",
    "                                   'district_3', 'district_4','district_5', 'district_6', 'district_7', 'district_8', \n",
    "                                   'district_9','district_10']), 1, inplace=True)\n",
    "    return df\n",
    "\n",
    "#--------------------------------\n",
    "def model_df():\n",
    "    '''This function reads in the clean 311 dataframe, applies all of the above functions to prepare it for modeling. \n",
    "    The function then returns a cleaned dataframe ready for modeling.'''\n",
    "    df= wrangle.clean_311(wrangle.get_311_data())\n",
    "    df= keep_info(df)\n",
    "    df= dummy_dept(df)\n",
    "    df= dummy_call_reason(df)\n",
    "    df= make_source_id_dummies(df)\n",
    "\n",
    "    return df\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def split(df, stratify_by= 'level_of_delay'):\n",
    "    \"\"\"\n",
    "    Crude train, validate, test split\n",
    "    To stratify, send in a column name\n",
    "    \"\"\"\n",
    "    if stratify_by == None:\n",
    "        train, test = train_test_split(df, test_size=.2, random_state=319)\n",
    "        train, validate = train_test_split(train, test_size=.3, random_state=319)\n",
    "    else:\n",
    "        train, test = train_test_split(df, test_size=.2, random_state=319, stratify=df[stratify_by])\n",
    "        train, validate = train_test_split(train, test_size=.3, random_state=319, stratify=train[stratify_by])\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "def separate_y(train, validate, test):\n",
    "    '''\n",
    "    This function will take the train, validate, and test dataframes and separate the target variable into its\n",
    "    own panda series\n",
    "    '''\n",
    "    \n",
    "    X_train = train.drop(columns=['level_of_delay'])\n",
    "    y_train = train.level_of_delay\n",
    "    X_validate = validate.drop(columns=['level_of_delay'])\n",
    "    y_validate = validate.level_of_delay\n",
    "    X_test = test.drop(columns=['level_of_delay'])\n",
    "    y_test = test.level_of_delay\n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "#------------------------------------\n",
    "def scale_data(X_train, X_validate, X_test):\n",
    "    '''\n",
    "    This function will scale numeric data using Min Max transform after \n",
    "    it has already been split into train, validate, and test.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    obj_col = ['dept', 'call_reason','source_id']\n",
    "    num_train = X_train.drop(columns = obj_col)\n",
    "    num_validate = X_validate.drop(columns = obj_col)\n",
    "    num_test = X_test.drop(columns = obj_col)\n",
    "    \n",
    "    \n",
    "    # Make the thing\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "   \n",
    "    # we only .fit on the training data\n",
    "    scaler.fit(num_train)\n",
    "    train_scaled = scaler.transform(num_train)\n",
    "    validate_scaled = scaler.transform(num_validate)\n",
    "    test_scaled = scaler.transform(num_test)\n",
    "    \n",
    "    # turn the numpy arrays into dataframes\n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=num_train.columns)\n",
    "    validate_scaled = pd.DataFrame(validate_scaled, columns=num_train.columns)\n",
    "    test_scaled = pd.DataFrame(test_scaled, columns=num_train.columns)\n",
    "    \n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "def split_separate_scale(df, stratify_by= 'level_of_delay'):\n",
    "    '''\n",
    "    This function will take in a dataframe\n",
    "    separate the dataframe into train, validate, and test dataframes\n",
    "    separate the target variable from train, validate and test\n",
    "    then it will scale the numeric variables in train, validate, and test\n",
    "    finally it will return all dataframes individually\n",
    "    '''\n",
    "    \n",
    "    # split data into train, validate, test\n",
    "    train, validate, test = split(df, stratify_by= 'level_of_delay')\n",
    "    \n",
    "     # seperate target variable\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = separate_y(train, validate, test)\n",
    "    \n",
    "    \n",
    "    # scale numeric variable\n",
    "    train_scaled, validate_scaled, test_scaled = scale_data(X_train, X_validate, X_test)\n",
    "    \n",
    "    return train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test, train_scaled, validate_scaled, test_scaled = split_separate_scale(df, stratify_by= 'level_of_delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['dept', 'call_reason', \n",
    "        'source_id', 'council_district'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = 'level_of_delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.late.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level of Delay by District"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://public.tableau.com/app/profile/lori.segovia/viz/LevelofDelaybyDistrict/District1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('all_311.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 and 5 downtown/central\n",
    "central = df[(df.district_1 == 1) | (df.district_5 == 1)]\n",
    "# 8 and 9\n",
    "north = df[(df.district_8 == 1) | (df.district_9 == 1)]\n",
    "# 4 and 3\n",
    "south = df[(df.district_4 == 1) | (df.district_3 == 1)]\n",
    "# 10 and 2\n",
    "east = df[(df.district_10 == 1) | (df.district_2 == 1)]\n",
    "#6 and 7\n",
    "west = df[(df.district_6 == 1) | (df.district_7 == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#north = df[(df.council_district == 8) | (df.council_district == 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#north.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north.council_district.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_days_north = north.days_before_or_after_due.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_days_south = south.days_before_or_after_due.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_days_east = east.days_before_or_after_due.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_days_west = west.days_before_or_after_due.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_days_central = central.days_before_or_after_due.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = 'there is no difference in the means'\n",
    "alt = 'there is a difference in the means'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.872594490711082 north\n",
      "4.978170052932353 south\n",
      "4.18188692035929 east\n",
      "7.958870137567458 west\n",
      "14.076052300885875 central\n"
     ]
    }
   ],
   "source": [
    "print(avg_days_north, 'north')\n",
    "print(avg_days_south, 'south')\n",
    "print(avg_days_east, 'east')\n",
    "print(avg_days_west, 'west')\n",
    "print(avg_days_central, 'central')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### north statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.857762505880725, 7.028488589933374e-12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# north and south\n",
    "t, p = stats.ttest_ind(north.days_before_or_after_due, south.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.022106395411587, 1.0490977398996743e-15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# north and east\n",
    "t, p = stats.ttest_ind(north.days_before_or_after_due, east.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5832575909418332, 0.11336583091735253)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# north and west\n",
    "t, p = stats.ttest_ind(north.days_before_or_after_due, west.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9.386685536146885, 6.2832508988218854e-21)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# north and central\n",
    "t, p = stats.ttest_ind(north.days_before_or_after_due, central.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### south statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.6280672811269723, 0.10351262206713681)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# south and east\n",
    "t, p = stats.ttest_ind(east.days_before_or_after_due, south.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.96809144442003, 2.4060042517140513e-09)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# south and west\n",
    "t, p = stats.ttest_ind(west.days_before_or_after_due, south.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.974145600931305, 1.1585699322880426e-88)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# south and central\n",
    "t, p = stats.ttest_ind(central.days_before_or_after_due, south.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### east statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.3509845898535895, 1.9781208221662076e-13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# east and west\n",
    "t, p = stats.ttest_ind(east.days_before_or_after_due, west.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-21.128323774383734, 5.830105513598658e-99)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# east and central\n",
    "t, p = stats.ttest_ind(east.days_before_or_after_due, central.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### west statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.711917980739397, 5.290778191232789e-37)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# west and central\n",
    "t, p = stats.ttest_ind(central.days_before_or_after_due, west.days_before_or_after_due)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
